# Bigdata_Analysis (25-1)
## 웹에서 Jupyter NoteBook실행하기
1. <code>pip install notebook</code> // jupyer노트북 install
2. <code>jupyter notebook</code> // 실행
## 파이썬 자료구조
### 데이터 표현
- 수치 데이터는 산술, 논리 연산 과정으로 사용되며 고정된 정수와 부동 소수점인 실수로 구성
- 비수치 데이터는 일상생활에서 사용하는 텍스트 또는 소리, 영상등과 같은 멀티미디어 데이터로 구성
- 빅데이터 시대로 접어들면서 대용량 데이터를 처리할 수 있게 되면서 비수치 데이터 세상이 도래
- 기본 연산 : <code> + 덧셈, - 뺄셈, *곱셈, ** 거듭제곱, /나누기, // 나눈 후 소수점이하의 수는 버리고 정수만 포함, %나눗셈 후 나머지만 구함.</code>
- 논리 연산 : <code> and , or , not </code>
- 자료형 <code>Tuples</code> : 튜플은 리스트와 유사한 시퀀스 데이터 자료형, 리스트와의 차이점은 리스트는 인덱스값을 변경 가능하다. 또한 list[]를 사용하지만 tuple()를 사용한다. 리스트가 더 많은 메모리를 차지한다.<br>
EX) <code>tuple[1:3]</code> 이면 index 1 부터 index 2까지를 의미한다. 끝 인덱스는 포함하지 않는다.<br>
EX) <code>(tuple + tuple) = (tuple *2)</code>
- 자료형 <code>Dictionary</code> : 쌍으로 만든 테이블 형식. key : value쌍으로 구성한다.
### 함수와 모듈
- Function : 반복적으로 사용되는 가치있는 부분을 한 그룹으로 묶어서 일정한 알고리즘을 사용해 결과값을 반환하는 식
- Module : 함수나 변수 또는 클래스를 모아 놓은 파일 - 프로그램 작성과 관리가 쉬워지고 공동작업이 편해지며 재활용이 쉽다. 주로 파이썬에서는 <code>import</code>를 사용하여 패키지를 가져온다. 

## 데이터 클린징
### 결측 데이터
1. 결측값 : 데이터 클린징 작업으로 데이터 누락값 - 결측값이 있는 상태로 데이터 분석을 진행하면 변수간의 관계가 외곡될 수 있다.
2. 결측값의 처리 : 제거(deletion), 대체(imputation)

### 결측 데이터 확인
1. isnull() : 결측 데이터이면 true, 유효한 데이터이면 false
2. notnull() : 유효한 데이터가 존재하면 true, 누락데이터면 false

### 결측치 개수 확인
- axis의 의미 : axis=0이면 세로 방향으로 계산(열), axis=1이면 가로 방향으로 계산()
1. 칼럼별 결측값 개수 구하기 : df.isnull().sum() => axis=0 생략된 것
2. 행 단위로 결측값 개수 구하기 : df.isnull().sum(1) => axis=1과 같은 
3. 행 단위로 실제값 개수 구하기 : df.notnull().sum()

### 결측치 제거
1. 행 삭제 데이터 프레임 : .dropna(axis=0)
2. 열 삭제 데이터 프레임 : .dropna(axis=1)

### 결측 데이터 대체
1. 결측값을 특정 값으로 채우기 : df.fillna(0)
2. 결측값을 특정 문자열로 채우기 : df.fillna('')
3. 결측값을 변수별 평균으로 대체 : df.fillna(df.mean())

### 결측 데이터 유의사항
1. null의 의미 : 숫자 0과 null은 다른 의미
2. 자료형
3. 결측치 제거 전 데이터 백업 

### 이상 데이터
1. 정상에서 벗어난 데이터를 이상치(outlier)라 한다.
2. 이상ㅎ나 데이터를 검출하는 것을 이상탐지

### 이상데이터 처리 방법
1. 단순 삭제 : 논리적 에러에 의해 발생한 경우, 해당 관측치 삭제
2. 다른 값으로 대체 : 데이터 개수가 적은 경우, 평균 등으로 대체
3. 변수화 : 삭제와 대체로 수립된 모델은 정확성에서 떨어질 수 있으므로, 이상값에 대한 파악 이후 대체
4. 리샘플링 : 해당 이상값을 분리해서 모델을 만들어 처리

### 중복 데이터 
- 데이터를 수집하는 과정 또는 데이터를 병합하는 단계에서 중복 데이터가 발생하면 분석에 영향을 미칠 수 있으므로, 유일한 키값을 관리해야한다.
- 데이터 분석 전에 중복 데이터를 확인하고 처리하는 데이터 클린징 작업 필요
- pandas에서 중복데이터 처리는 duplicated() 사용. drop_duplicates() 사용